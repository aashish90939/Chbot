# HSRW Chatbot

The **HSRW Chatbot** is a comprehensive tool designed to scrape, process, and interact with data from the HSRW university website. It uses **Scrapy** for web scraping, **ChromaDB** for database storage, and integrates **OpenAI LLM** for intelligent chatbot capabilities, accessible via a **Streamlit GUI**.

---

## ğŸš€ Features
- **Web Scraping**: Crawl the HSRW university website using Scrapy.
- **Data Processing**: Process scraped markdown data into a structured format for storage.
- **Vector Database**: Store and retrieve data using ChromaDB.
- **GUI with Streamlit**: A user-friendly interface for interacting with the chatbot.
- **OpenAI LLM Integration**: Generate intelligent responses using a language model.

---

## ğŸ“‚ Project Structure
```plaintext
HSRW_CHATBOT/
â”œâ”€â”€ .idea/                  # Project-specific settings for IDE
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ assets/             # Contains image assets for GUI
â”‚   â”‚   â”œâ”€â”€ ai.png
â”‚   â”‚   â”œâ”€â”€ image1.png
â”‚   â”‚   â”œâ”€â”€ image1.svg
â”‚   â”‚   â””â”€â”€ user.png
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ CONFIG.py       # Configuration settings
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ frontend.py     # GUI implementation with Streamlit
â”‚   â”œâ”€â”€ helper/
â”‚   â”‚   â”œâ”€â”€ data_preprocesser.py  # Markdown data processing
â”‚   â”‚   â””â”€â”€ vizualization.py      # Visualization tools
â”‚   â””â”€â”€ scrapper/
â”‚       â””â”€â”€ website_scrapper/    # Scrapy project folder
â”‚           â”œâ”€â”€ spiders/         # Scrapy spiders for crawling
â”‚           â”œâ”€â”€ items.py         # Scrapy item definitions
â”‚           â”œâ”€â”€ pipelines.py     # Scrapy pipelines
â”‚           â”œâ”€â”€ settings.py      # Scrapy settings
â”‚           â””â”€â”€ scrapy.cfg       # Scrapy configuration file
â”œâ”€â”€ .env                     # Environment variables (ignored in Git)
â”œâ”€â”€ .gitignore               # Files and folders ignored by Git
â”œâ”€â”€ Dockerfile               # Docker container setup
â”œâ”€â”€ docker-compose.yml       # Docker Compose setup
â”œâ”€â”€ HSRW_Chatbot.iml         # Project file for IDE
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ wait-for-it.sh           # Shell script for service initialization
â””â”€â”€ README.md                # Documentation file


ğŸ› ï¸ Technologies Used
Web Scraping: Scrapy
Vector Database: ChromaDB
Frontend: Streamlit
LLM Integration: OpenAI API
Docker: Containerized deployment
#ğŸš€ Getting Started
##Prerequisites
Python 3.8+
Docker (if using containerized deployment)
Installation
1.Clone the repository:
2.Install Python dependencies:
3.Set up your .env file: for apis

#Running the Application
##Option 1: Run Locally
1.	Start the Scrapy spider to crawl the website:
cd app/scrapper/website_scrapper
scrapy crawl <spider_name>
2.	Process the scraped data:
python app/helper/data_preprocesser.py
3.	Launch the chatbot interface:
python app/frontend/frontend.py
##Option 2: Run with Docker
1.	Build the Docker container:
docker-compose build
2.	Start the container:
docker-compose up

![image](https://github.com/user-attachments/assets/66050eb0-f3c6-4489-8ff4-2b4da4608da3)

##ğŸ“œ License
This project is licensed under @@shish


